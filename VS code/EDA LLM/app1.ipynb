{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "e15a90b8",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Requirement already satisfied: ollama in c:\\users\\hanshu\\anaconda3\\lib\\site-packages (0.5.1)\n",
      "Requirement already satisfied: httpx>=0.27 in c:\\users\\hanshu\\anaconda3\\lib\\site-packages (from ollama) (0.27.0)\n",
      "Requirement already satisfied: pydantic>=2.9 in c:\\users\\hanshu\\anaconda3\\lib\\site-packages (from ollama) (2.11.7)\n",
      "Requirement already satisfied: anyio in c:\\users\\hanshu\\anaconda3\\lib\\site-packages (from httpx>=0.27->ollama) (4.2.0)\n",
      "Requirement already satisfied: certifi in c:\\users\\hanshu\\anaconda3\\lib\\site-packages (from httpx>=0.27->ollama) (2025.4.26)\n",
      "Requirement already satisfied: httpcore==1.* in c:\\users\\hanshu\\anaconda3\\lib\\site-packages (from httpx>=0.27->ollama) (1.0.2)\n",
      "Requirement already satisfied: idna in c:\\users\\hanshu\\anaconda3\\lib\\site-packages (from httpx>=0.27->ollama) (3.7)\n",
      "Requirement already satisfied: sniffio in c:\\users\\hanshu\\anaconda3\\lib\\site-packages (from httpx>=0.27->ollama) (1.3.0)\n",
      "Requirement already satisfied: h11<0.15,>=0.13 in c:\\users\\hanshu\\anaconda3\\lib\\site-packages (from httpcore==1.*->httpx>=0.27->ollama) (0.14.0)\n",
      "Requirement already satisfied: annotated-types>=0.6.0 in c:\\users\\hanshu\\anaconda3\\lib\\site-packages (from pydantic>=2.9->ollama) (0.6.0)\n",
      "Requirement already satisfied: pydantic-core==2.33.2 in c:\\users\\hanshu\\anaconda3\\lib\\site-packages (from pydantic>=2.9->ollama) (2.33.2)\n",
      "Requirement already satisfied: typing-extensions>=4.12.2 in c:\\users\\hanshu\\anaconda3\\lib\\site-packages (from pydantic>=2.9->ollama) (4.14.1)\n",
      "Requirement already satisfied: typing-inspection>=0.4.0 in c:\\users\\hanshu\\anaconda3\\lib\\site-packages (from pydantic>=2.9->ollama) (0.4.1)\n",
      "Note: you may need to restart the kernel to use updated packages.\n"
     ]
    }
   ],
   "source": [
    "\n",
    " pip install ollama\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "46479390",
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import seaborn as sns\n",
    "import matplotlib.pyplot as plt\n",
    "import ollama"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "a3d25938",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Id</th>\n",
       "      <th>SepalLengthCm</th>\n",
       "      <th>SepalWidthCm</th>\n",
       "      <th>PetalLengthCm</th>\n",
       "      <th>PetalWidthCm</th>\n",
       "      <th>Species</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>1</td>\n",
       "      <td>5.1</td>\n",
       "      <td>3.5</td>\n",
       "      <td>1.4</td>\n",
       "      <td>0.2</td>\n",
       "      <td>Iris-setosa</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>2</td>\n",
       "      <td>4.9</td>\n",
       "      <td>3.0</td>\n",
       "      <td>1.4</td>\n",
       "      <td>0.2</td>\n",
       "      <td>Iris-setosa</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>3</td>\n",
       "      <td>4.7</td>\n",
       "      <td>3.2</td>\n",
       "      <td>1.3</td>\n",
       "      <td>0.2</td>\n",
       "      <td>Iris-setosa</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>4</td>\n",
       "      <td>4.6</td>\n",
       "      <td>3.1</td>\n",
       "      <td>1.5</td>\n",
       "      <td>0.2</td>\n",
       "      <td>Iris-setosa</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>5</td>\n",
       "      <td>5.0</td>\n",
       "      <td>3.6</td>\n",
       "      <td>1.4</td>\n",
       "      <td>0.2</td>\n",
       "      <td>Iris-setosa</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>145</th>\n",
       "      <td>146</td>\n",
       "      <td>6.7</td>\n",
       "      <td>3.0</td>\n",
       "      <td>5.2</td>\n",
       "      <td>2.3</td>\n",
       "      <td>Iris-virginica</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>146</th>\n",
       "      <td>147</td>\n",
       "      <td>6.3</td>\n",
       "      <td>2.5</td>\n",
       "      <td>5.0</td>\n",
       "      <td>1.9</td>\n",
       "      <td>Iris-virginica</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>147</th>\n",
       "      <td>148</td>\n",
       "      <td>6.5</td>\n",
       "      <td>3.0</td>\n",
       "      <td>5.2</td>\n",
       "      <td>2.0</td>\n",
       "      <td>Iris-virginica</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>148</th>\n",
       "      <td>149</td>\n",
       "      <td>6.2</td>\n",
       "      <td>3.4</td>\n",
       "      <td>5.4</td>\n",
       "      <td>2.3</td>\n",
       "      <td>Iris-virginica</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>149</th>\n",
       "      <td>150</td>\n",
       "      <td>5.9</td>\n",
       "      <td>3.0</td>\n",
       "      <td>5.1</td>\n",
       "      <td>1.8</td>\n",
       "      <td>Iris-virginica</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>150 rows Ã— 6 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "      Id  SepalLengthCm  SepalWidthCm  PetalLengthCm  PetalWidthCm  \\\n",
       "0      1            5.1           3.5            1.4           0.2   \n",
       "1      2            4.9           3.0            1.4           0.2   \n",
       "2      3            4.7           3.2            1.3           0.2   \n",
       "3      4            4.6           3.1            1.5           0.2   \n",
       "4      5            5.0           3.6            1.4           0.2   \n",
       "..   ...            ...           ...            ...           ...   \n",
       "145  146            6.7           3.0            5.2           2.3   \n",
       "146  147            6.3           2.5            5.0           1.9   \n",
       "147  148            6.5           3.0            5.2           2.0   \n",
       "148  149            6.2           3.4            5.4           2.3   \n",
       "149  150            5.9           3.0            5.1           1.8   \n",
       "\n",
       "            Species  \n",
       "0       Iris-setosa  \n",
       "1       Iris-setosa  \n",
       "2       Iris-setosa  \n",
       "3       Iris-setosa  \n",
       "4       Iris-setosa  \n",
       "..              ...  \n",
       "145  Iris-virginica  \n",
       "146  Iris-virginica  \n",
       "147  Iris-virginica  \n",
       "148  Iris-virginica  \n",
       "149  Iris-virginica  \n",
       "\n",
       "[150 rows x 6 columns]"
      ]
     },
     "execution_count": 4,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# load dataset\n",
    "url = r\"C:\\Users\\Hanshu\\Desktop\\excel data\\Iris.csv\"\n",
    "df = pd.read_csv(url)\n",
    "df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "c21050ca",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "               Id  SepalLengthCm  SepalWidthCm  PetalLengthCm  PetalWidthCm\n",
      "count  150.000000     150.000000    150.000000     150.000000    150.000000\n",
      "mean    75.500000       5.843333      3.054000       3.758667      1.198667\n",
      "std     43.445368       0.828066      0.433594       1.764420      0.763161\n",
      "min      1.000000       4.300000      2.000000       1.000000      0.100000\n",
      "25%     38.250000       5.100000      2.800000       1.600000      0.300000\n",
      "50%     75.500000       5.800000      3.000000       4.350000      1.300000\n",
      "75%    112.750000       6.400000      3.300000       5.100000      1.800000\n",
      "max    150.000000       7.900000      4.400000       6.900000      2.500000\n"
     ]
    }
   ],
   "source": [
    "# display dataset info\n",
    "print(df.describe())\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "bb006aac",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Missing Values:\n",
      " Id               0\n",
      "SepalLengthCm    0\n",
      "SepalWidthCm     0\n",
      "PetalLengthCm    0\n",
      "PetalWidthCm     0\n",
      "Species          0\n",
      "dtype: int64\n"
     ]
    }
   ],
   "source": [
    "# missing values check\n",
    "print(\"\\nMissing Values:\\n\", df.isnull().sum())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "f14e00fa",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "* AI-Generated Insights:\n",
      " ## Insights from the Dataset Summary\n",
      "\n",
      "**Overall:**\n",
      "\n",
      "* The dataset contains information on 150 flower specimens.\n",
      "* The data covers a wide range of features, including:\n",
      "    * **Petal length and width**: These features are relatively consistent, with a mean of 5.8 and standard deviation of 0.8.\n",
      "    * **Sepal length and width**: These features have a larger variability, with a mean of 75.5 and standard deviation of 43.4.\n",
      "    * **Petal color**: This feature has a relatively lower mean of 1.3 compared to the other features.\n",
      "    * **Sepal length**: This feature has a higher mean of 75.5 compared to other features.\n",
      "    * **Sepal width**: This feature has a lower mean of 3.0 compared to other features.\n",
      "\n",
      "**Additional observations:**\n",
      "\n",
      "* The minimum and 25th percentile values indicate that the smallest petals are 1 cm long and the smallest sepal length is 4.3 cm.\n",
      "* The 75th percentile and maximum values indicate that the largest petals are 6.9 cm long and the largest sepal length is 7.9 cm.\n",
      "* The dataset likely contains outliers with the maximum petal length exceeding 7.9 cm.\n",
      "\n",
      "**Further analysis:**\n",
      "\n",
      "* It would be interesting to analyze the data further to identify trends and relationships between different features.\n",
      "* Statistical tests could be used to determine the significance of differences between groups defined by these features.\n",
      "* Visualization techniques could be employed to create clear and insightful charts and graphs.\n"
     ]
    }
   ],
   "source": [
    "import ollama\n",
    "\n",
    "def generate_insights(df_summary):                                                                         # wuth def keyword i created a fun\n",
    "    prompt = f'analyze the dataset summary and provide insights:\\n\\n{df_summary}'\n",
    "    response = ollama.chat(model = 'gemma:2b', messages=[{'role':'user' , 'content': prompt}])\n",
    "    return response['message']['content']\n",
    "\n",
    "# generate AI Insights\n",
    "summary = df.describe().to_string()                                #describe()--> descriptive statistics        # to_string() --> converting every thin to the string \n",
    "insights = generate_insights(summary)\n",
    "print('\\n* AI-Generated Insights:\\n' , insights)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "id": "cfdcb1d5",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "* Running on local URL:  http://127.0.0.1:7862\n",
      "\n",
      "Could not create share link. Please check your internet connection or our status page: https://status.gradio.app.\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<div><iframe src=\"http://127.0.0.1:7862/\" width=\"100%\" height=\"500\" allow=\"autoplay; camera; microphone; clipboard-read; clipboard-write;\" frameborder=\"0\" allowfullscreen></iframe></div>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/plain": []
     },
     "execution_count": 14,
     "metadata": {},
     "output_type": "execute_result"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\Hanshu\\AppData\\Local\\Temp\\ipykernel_11284\\2822345233.py:14: FutureWarning: A value is trying to be set on a copy of a DataFrame or Series through chained assignment using an inplace method.\n",
      "The behavior will change in pandas 3.0. This inplace method will never work because the intermediate object on which we are setting values always behaves as a copy.\n",
      "\n",
      "For example, when doing 'df[col].method(value, inplace=True)', try using 'df.method({col: value}, inplace=True)' or df[col] = df[col].method(value) instead, to perform the operation inplace on the original object.\n",
      "\n",
      "\n",
      "  df[col].fillna(df[col].median(), inplace=True)\n",
      "C:\\Users\\Hanshu\\AppData\\Local\\Temp\\ipykernel_11284\\2822345233.py:19: FutureWarning: A value is trying to be set on a copy of a DataFrame or Series through chained assignment using an inplace method.\n",
      "The behavior will change in pandas 3.0. This inplace method will never work because the intermediate object on which we are setting values always behaves as a copy.\n",
      "\n",
      "For example, when doing 'df[col].method(value, inplace=True)', try using 'df.method({col: value}, inplace=True)' or df[col] = df[col].method(value) instead, to perform the operation inplace on the original object.\n",
      "\n",
      "\n",
      "  df[col].fillna(df[col].mode()[0] , inplace=True)\n"
     ]
    }
   ],
   "source": [
    "import gradio as gr\n",
    "import pandas as pd\n",
    "import matplotlib.pyplot as plt\n",
    "import seaborn as sns\n",
    "import ollama\n",
    "\n",
    "\n",
    "# function to perform EDA and Generate visualization\n",
    "def eda_analysis(file_path):\n",
    "    df = pd.read_csv(file_path)   # my datset read file path (app.py(in EDA LLM Folder ))\n",
    "    \n",
    "    # fill missing values with median for numeric columns\n",
    "    for col in df.select_dtypes(include=['number']).columns:          # for col--> for entire column\n",
    "        df[col].fillna(df[col].median(), inplace=True)\n",
    "        \n",
    "        \n",
    "    # fill missing values with median for categorical columns\n",
    "    for col in df.select_dtypes(include=['object']).columns:\n",
    "        df[col].fillna(df[col].mode()[0] , inplace=True)\n",
    "            \n",
    "     # data summary\n",
    "    summary = df.describe(include='all').to_string()\n",
    "    \n",
    "    \n",
    "    # missing values\n",
    "    missing_values = df.isnull().sum().to_string() \n",
    "    \n",
    "    # Generate AI Insights\n",
    "    insights = generate_ai_insights(summary) \n",
    "    \n",
    "    #Generate data viz\n",
    "    plot_paths = generate_visualizations(df)\n",
    "    \n",
    "    return f\"\\n Data Loaded Successfully!\\n\\n Summary:\\n{summary}\\n\\n Missing Values:\\n{missing_values}\\n\\n AI Insights:\\n{insights}\", plot_paths\n",
    "\n",
    "# AI-Powered Insights using Mistral-7B (Ollama)\n",
    "def generate_ai_insights(df_summary):\n",
    "    prompt = f\"Analyze the dataset summary and provide insights:\\n\\n{df_summary}\"\n",
    "    response = ollama.chat(model=\"gemma:2b\", messages=[{\"role\": \"user\", \"content\": prompt}])\n",
    "    return response['message']['content']\n",
    "\n",
    "# Function to Generate Data Visualizations\n",
    "def generate_visualizations(df):\n",
    "    plot_paths = []\n",
    "    \n",
    "    # Histograms for Numeric Columns\n",
    "    for col in df.select_dtypes(include=['number']).columns:\n",
    "        plt.figure(figsize=(6,4))\n",
    "        sns.histplot(df[col], bins=30, kde=True, color=\"blue\")\n",
    "        plt.title(f\"Distribution of {col}\")\n",
    "        path = f\"{col}_distribution.png\"\n",
    "        plt.savefig(path)\n",
    "        plot_paths.append(path)\n",
    "        plt.close()\n",
    "    \n",
    "    # Correlation Heatmap (only numeric columns)\n",
    "    numeric_df = df.select_dtypes(include=['number'])\n",
    "    if not numeric_df.empty:\n",
    "        plt.figure(figsize=(8,5))\n",
    "        sns.heatmap(numeric_df.corr(), annot=True, cmap='coolwarm', fmt=\".2f\", linewidths=0.5)\n",
    "        plt.title(\"Correlation Heatmap\")\n",
    "        path = \"correlation_heatmap.png\"\n",
    "        plt.savefig(path)\n",
    "        plot_paths.append(path)\n",
    "        plt.close()\n",
    "\n",
    "    return plot_paths\n",
    "\n",
    "# Gradio Interface\n",
    "demo = gr.Interface(\n",
    "    fn=eda_analysis,\n",
    "    inputs=gr.File(type=\"filepath\"),\n",
    "    outputs=[gr.Textbox(label=\"EDA Report\"), gr.Gallery(label=\"Data Visualizations\")],\n",
    "    title=\"ðŸ“Š LLM-Powered Exploratory Data Analysis (EDA)\",\n",
    "    description=\"Upload any dataset CSV file and get automated EDA insights with AI-powered analysis and visualizations.\"\n",
    ")\n",
    "\n",
    "# Launch the Gradio App\n",
    "demo.launch(share=True)\n",
    "\n",
    "            \n",
    "            \n",
    "            \n",
    "        \n",
    "        "
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "base",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.7"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
